{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":37705,"sourceType":"datasetVersion","datasetId":29561}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AI6103 Final Project\n<br>\n\n## Team Details:\n### 1. Shanthakumar Karan (G2403054G) karan013@e.ntu.edu.sg\n### 2. Ramakrishnan Shivaraman (G2402819B) shivaram003@e.ntu.edu.sg\n### 3. Shrikant Ameya Sunil (G2403333J) ameyasun001@e.ntu.edu.sg","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.utils.data import DataLoader, Subset\nfrom torchvision import transforms, datasets\nfrom torchvision.utils import save_image\nfrom tqdm import tqdm\nfrom math import log10\nfrom torch.cuda.amp import GradScaler, autocast\nimport matplotlib.pyplot as plt\n\nimport torch.backends.cudnn as cudnn\ncudnn.benchmark = True\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMG_SIZE = 64 \nBATCH_SIZE = 8\nDATASET_DIR = \"/kaggle/input/celeba-dataset/img_align_celeba\" \n\ntransform = transforms.Compose([\n    transforms.CenterCrop(178),\n    transforms.Resize(IMG_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])  \n])\n\ndataset = datasets.ImageFolder(root=DATASET_DIR, transform=transform)\n\nsubset_size = 5000 \nindices = torch.randperm(len(dataset))[:subset_size]\ndataset = Subset(dataset, indices)\n\ndataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n\n# Define U-Net\nclass UNet(nn.Module):\n    def __init__(self):\n        super(UNet, self).__init__()\n        \n        # Encoder\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n        )\n\n        # Middle Layers\n        self.middle = nn.Sequential(\n            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n            nn.ReLU(),\n        )\n\n        # Decoder\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),\n            nn.Tanh(),\n        )\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.middle(x)\n        x = self.decoder(x)\n        assert x.shape[-2:] == (IMG_SIZE, IMG_SIZE), f\"Output shape mismatch: {x.shape}\"\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_psnr(original, generated):\n    mse = torch.mean((original - generated) ** 2)\n    if mse == 0:\n        return 100  \n    psnr = 10 * log10(1 / mse.item())\n    return psnr\n\ndef pixel_accuracy(original, generated, threshold=0.1):\n    return torch.mean((torch.abs(original - generated) < threshold).float()).item()\n\ndef plot_results(loss_history, psnr_history):\n    plt.figure(figsize=(10, 5))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(loss_history, label='Training Loss')\n    plt.title(\"Training Loss Over Epochs\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n\n    plt.subplot(1, 2, 2)\n    plt.plot(psnr_history, label='PSNR (dB)', color='orange')\n    plt.title(\"PSNR Over Epochs\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"PSNR (dB)\")\n    plt.legend()\n\n    plt.subplot(1, 3, 3)\n    plt.plot(accuracy_history, label=\"Pixel Accuracy (%)\", color=\"green\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy (%)\")\n    plt.title(\"Pixel Accuracy Over Epochs\")\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Generate Sample Images","metadata":{}},{"cell_type":"code","source":"import torch\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef denormalize(image_tensor):\n    return (image_tensor + 1) / 2\n\ndef plot_generated_faces(images, num_images=8):\n    print(\"Tensor shape:\", images.shape)\n    print(\"Tensor dtype:\", images.dtype)\n    print(\"Tensor min/max:\", images.min().item(), images.max().item())\n\n    if images.shape[1] == 3:  \n        images = images.permute(0, 2, 3, 1)  \n\n    num_images = min(num_images, len(images))\n\n    cols = int(num_images**0.5)\n    rows = (num_images // cols) + (num_images % cols > 0)\n    fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))\n\n    for i, ax in enumerate(axes.flatten()):\n        if i < num_images:\n            img = denormalize(images[i].detach().cpu()).clip(0, 1).numpy()\n            img = img.astype(np.float32) \n            ax.imshow(img)\n            ax.axis('off')\n        else:\n            ax.axis('off') \n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Learning Rates","metadata":{}},{"cell_type":"code","source":"criterion_mse = nn.MSELoss()\nscaler = GradScaler() \nEPOCHS = 15\n\nrates = [1e-2, 1e-3, 1e-4]\n\nfor rate in rates:\n    loss_history = []\n    psnr_history = []\n    accuracy_history = []\n    model = UNet().to(device)\n    optimizer = Adam(model.parameters(), lr=rate)\n    # scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n    \n    \n    for epoch in range(EPOCHS):\n        model.train()\n        running_loss = 0.0\n        psnr_total = 0.0\n        accuracy_total = 0.0 \n    \n        for images, _ in tqdm(dataloader):\n            images = images.to(device)\n    \n            # Adding noise\n            noise = torch.randn_like(images) * 0.1\n            noisy_images = images + noise.to(device)\n            noisy_images = torch.clip(noisy_images, -1, 1)\n    \n            with autocast():\n                outputs = model(noisy_images)\n    \n                mse_loss = criterion_mse(outputs, images)\n                total_loss = mse_loss\n    \n            optimizer.zero_grad()\n            scaler.scale(total_loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n    \n            running_loss += total_loss.item()\n    \n            psnr_total += calculate_psnr(images, outputs)\n            accuracy_total += pixel_accuracy(images, outputs)\n    \n            torch.cuda.empty_cache()\n    \n        avg_loss = running_loss / len(dataloader)\n        avg_psnr = psnr_total / len(dataloader)\n        avg_accuracy = accuracy_total / len(dataloader) \n    \n        loss_history.append(avg_loss)\n        psnr_history.append(avg_psnr)\n        accuracy_history.append(avg_accuracy)\n    \n        # scheduler.step()\n        print(f\"Epoch [{epoch + 1}/{EPOCHS}], Loss: {avg_loss:.4f}, PSNR: {avg_psnr:.2f} dB, Accuracy: {avg_accuracy * 100:.2f}%\")\n    plot_results(loss_history, psnr_history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Without any Regularization Techniques","metadata":{}},{"cell_type":"markdown","source":"### Image Size set to 64. Without Noise.","metadata":{}},{"cell_type":"code","source":"criterion_mse = nn.MSELoss()\nscaler = GradScaler()\nEPOCHS = 100\n\nRATE = 1e-4\n\nloss_history = []\npsnr_history = []\naccuracy_history = []\nbase_model = UNet().to(device)\noptimizer = Adam(base_model.parameters(), lr=RATE)\n# scheduler = StepLR(optimizer, step_size=25, gamma=0.5)\n\nfor epoch in range(EPOCHS):\n    base_model.train()\n    running_loss = 0.0\n    psnr_total = 0.0\n    accuracy_total = 0.0 \n\n    for images, _ in tqdm(dataloader):\n        images = images.to(device)\n\n        # Adding noise\n        # noise = torch.randn_like(images) * 0.1\n        # noisy_images = images + noise.to(device)\n        # noisy_images = torch.clip(noisy_images, -1, 1)\n\n        with autocast():\n            base_outputs = base_model(images)\n\n            mse_loss = criterion_mse(base_outputs, images)\n            total_loss = mse_loss\n\n        optimizer.zero_grad()\n        scaler.scale(total_loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        running_loss += total_loss.item()\n\n        psnr_total += calculate_psnr(images, base_outputs)\n        accuracy_total += pixel_accuracy(images, base_outputs)\n\n        torch.cuda.empty_cache()\n\n    # Store average metrics\n    avg_loss = running_loss / len(dataloader)\n    avg_psnr = psnr_total / len(dataloader)\n    avg_accuracy = accuracy_total / len(dataloader) \n\n    loss_history.append(avg_loss)\n    psnr_history.append(avg_psnr)\n    accuracy_history.append(avg_accuracy)\n\n    # scheduler.step()\n    print(f\"Epoch [{epoch + 1}/{EPOCHS}], Loss: {avg_loss:.4f}, PSNR: {avg_psnr:.2f} dB, Accuracy: {avg_accuracy * 100:.2f}%\")\nplot_results(loss_history, psnr_history)\nplot_generated_faces(base_outputs, num_images=8)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1. STEP LR WITH WEIGHT DECAY","metadata":{}},{"cell_type":"markdown","source":"### LR with weight Decay","metadata":{}},{"cell_type":"code","source":"criterion_mse = nn.MSELoss()\nscaler = GradScaler()\nEPOCHS = 100\n\nRATE = 1e-4\n\nloss_history = []\npsnr_history = []\naccuracy_history = []\nmodel = UNet().to(device)\noptimizer = Adam(model.parameters(), lr=RATE, weight_decay=2e-6)\nscheduler = StepLR(optimizer, step_size=25, gamma=0.5)\n\nfor epoch in range(EPOCHS):\n    model.train()\n    running_loss = 0.0\n    psnr_total = 0.0\n    accuracy_total = 0.0  \n\n    for images, _ in tqdm(dataloader):\n        images = images.to(device)\n\n        # Adding noise\n        # noise = torch.randn_like(images) * 0.1\n        # noisy_images = images + noise.to(device)\n        # noisy_images = torch.clip(noisy_images, -1, 1)\n\n        with autocast():\n            outputs = model(images)\n\n            mse_loss = criterion_mse(outputs, images)\n            total_loss = mse_loss\n\n        optimizer.zero_grad()\n        scaler.scale(total_loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        running_loss += total_loss.item()\n\n        psnr_total += calculate_psnr(images, outputs)\n        accuracy_total += pixel_accuracy(images, outputs)\n\n        torch.cuda.empty_cache()\n\n    avg_loss = running_loss / len(dataloader)\n    avg_psnr = psnr_total / len(dataloader)\n    avg_accuracy = accuracy_total / len(dataloader)\n\n    loss_history.append(avg_loss)\n    psnr_history.append(avg_psnr)\n    accuracy_history.append(avg_accuracy)\n\n    scheduler.step()\n    print(f\"Epoch [{epoch + 1}/{EPOCHS}], Loss: {avg_loss:.4f}, PSNR: {avg_psnr:.2f} dB, Accuracy: {avg_accuracy * 100:.2f}%\")\nplot_results(loss_history, psnr_history)\nplot_generated_faces(outputs, num_images=8)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2. NOISE INJECTION","metadata":{}},{"cell_type":"code","source":"criterion_mse = nn.MSELoss()\nscaler = GradScaler()\nEPOCHS = 100\n\nRATE = 1e-4\n\nloss_history = []\npsnr_history = []\naccuracy_history = []\nmodel = UNet().to(device)\noptimizer = Adam(model.parameters(), lr=RATE, weight_decay=2e-6)\n# scheduler = StepLR(optimizer, step_size=25, gamma=1e-6)\n\nfor epoch in range(EPOCHS):\n    model.train()\n    running_loss = 0.0\n    psnr_total = 0.0\n    accuracy_total = 0.0  \n\n    for images, _ in tqdm(dataloader):\n        images = images.to(device)\n        \n        noise = torch.randn_like(images) * 0.001\n        noisy_images = images + noise.to(device)\n        noisy_images = torch.clip(noisy_images, -1, 1)\n\n        noisy_images = noisy_images.to(device)\n\n        with autocast(): \n            outputs = model(noisy_images)\n\n            mse_loss = criterion_mse(outputs, images)\n            total_loss = mse_loss\n\n\n        optimizer.zero_grad()\n        scaler.scale(total_loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        running_loss += total_loss.item()\n\n        psnr_total += calculate_psnr(images, outputs)\n        accuracy_total += pixel_accuracy(images, outputs)\n\n        torch.cuda.empty_cache()\n\n    avg_loss = running_loss / len(dataloader)\n    avg_psnr = psnr_total / len(dataloader)\n    avg_accuracy = accuracy_total / len(dataloader) \n\n    loss_history.append(avg_loss)\n    psnr_history.append(avg_psnr)\n    accuracy_history.append(avg_accuracy)\n\n    # scheduler.step()\n    print(f\"Epoch [{epoch + 1}/{EPOCHS}], Loss: {avg_loss:.4f}, PSNR: {avg_psnr:.2f} dB, Accuracy: {avg_accuracy * 100:.2f}%\")\nplot_results(loss_history, psnr_history)\nplot_generated_faces(outputs, num_images=8)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}